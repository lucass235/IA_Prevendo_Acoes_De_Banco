{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#  biblioteca numpy que é usada para trabalhar com arrays e matrizes multidimensionais\n",
    "import numpy as np \n",
    "#  biblioteca pandas que é usada para trabalhar com dados tabulares e séries temporais \n",
    "import matplotlib.pyplot as plt\n",
    "#  biblioteca matplotlib que é usada para plotar gráficos \n",
    "import pandas as pd\n",
    "# biblioteca pandas_datareader que é usada para importar dados do Yahoo Finance\n",
    "import pandas_datareader as web\n",
    "# biblioteca datetime que é usada para trabalhar com datas e horas \n",
    "import datetime as dt\n",
    "\n",
    "# biblioteca keras que é usada para criar e treinar redes neurais\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Sequential é uma pilha de camadas onde cada camada tem exatamente um tensor de entrada e um tensor de saída \n",
    "from tensorflow.keras.models import Sequential\n",
    "# Dense é uma camada de neurônios totalmente conectados, onde cada neurônio está conectado a todos os neurônios na próxima camada\n",
    "# Dropout é uma técnica de regularização que previne o overfitting \n",
    "# LSTM é uma camada de rede neural recorrente que é usada para processar sequências de dados \n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banco = 'BBAS3.SA' # Banco do Brasil\n",
    "\n",
    "inicio = dt.datetime(2012,1,1) # data de inicio\n",
    "fim = dt.datetime(2022,11,18) # data de hoje\n",
    "\n",
    "dados = web.DataReader(banco, 'yahoo', inicio, fim) # pega os dados do yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados\n",
    "normalizando = MinMaxScaler(feature_range=(0,1)) # normalizando os dados entre 0 e 1\n",
    "dados_normalizados = normalizando.fit_transform(dados['Close'].values.reshape(-1,1)) # normalizando os dados de fechamento \n",
    "\n",
    "previsao_dias = 3 # dias para prever\n",
    "\n",
    "x_treinar, y_treinar = [], []\n",
    "\n",
    "# pegando os dados de fechamento e colocando em x_treinar e y_label\n",
    "for x in range(previsao_dias, len(dados_normalizados)):\n",
    "    x_treinar.append(dados_normalizados[x-previsao_dias:x, 0])\n",
    "    y_treinar.append(dados_normalizados[x, 0])\n",
    "\n",
    "x_treinar, y_treinar = np.array(x_treinar), np.array(y_treinar) # transformando em array numpy \n",
    "x_treinar = np.reshape(x_treinar, (x_treinar.shape[0], x_treinar.shape[1], 1)) # redimensionando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_treinar e y_treinar\n",
    "\n",
    "- O x_treinar é o conjunto de dados que será utilizado para treinar o modelo, ou seja, o conjunto de dados que será utilizado para que o modelo aprenda a classificar os dados.\n",
    "\n",
    "- E o y_treinar difere do x_treinar, pois o y_treinar é o conjunto de dados que será utilizado para treinar o modelo, ou seja, o conjunto de dados que será utilizado para que o modelo aprenda a classificar os dados.\n",
    "\n",
    "## x_treinar.append(dados_normalizados[x-previsao_dias:x, 0])\n",
    "\n",
    "- O x_treinar.append() é utilizado para adicionar os dados normalizados do conjunto de dados, que será utilizado para treinar o modelo, no conjunto de dados x_treinar.\n",
    "\n",
    "## y_treinar.append(dados_normalizados[x, 0])\n",
    "\n",
    "- O y_treinar.append() é utilizado para adicionar os dados normalizados do conjunto de dados, que será utilizado para treinar o modelo, no conjunto de dados y_treinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_treinar.shape)\n",
    "print(y_treinar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construindo o modelo de rede neural LSTM\n",
    "\n",
    "modelo = Sequential()\n",
    "\n",
    "# camada de entrada e primeira camada oculta com 25 neurônios e 3 dias de previsão \n",
    "modelo.add(LSTM(units=25, return_sequences=True, input_shape=(x_treinar.shape[1], 1))) \n",
    "# camada de dropout para evitar overfitting \n",
    "modelo.add(Dropout(0.2)) # camada de dropout para evitar overfitting \n",
    "# 50 neurônios, return_sequences=True para retornar a sequência, \n",
    "# input_shape=(x_treinar.shape[1], 1) para pegar a quantidade de dias e \n",
    "# 1 para pegar o valor de fechamento\n",
    "modelo.add(LSTM(units=25, return_sequences=True)) \n",
    "# camada de dropout para evitar overfitting \n",
    "modelo.add(Dropout(0.2)) \n",
    "# 50 neurônios, return_sequences=True para retornar a sequência\n",
    "modelo.add(LSTM(units=25))\n",
    "# camada de dropout para evitar overfitting\n",
    "modelo.add(Dropout(0.2))\n",
    "# camada de saída com 1 neurônio\n",
    "modelo.add(Dense(units=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotações do código\n",
    "\n",
    "### Sequential\n",
    "\n",
    "- É uma pilha de camadas onde cada camada tem exatamente um tensor de entrada e um tensor de saída. (Ex: camada de entrada, camada oculta, camada de saída), tensor é um array multidimensional.\n",
    "\n",
    "### overfitting\n",
    "\n",
    "- overfitting: quando o modelo se ajusta muito bem aos dados de treino, mas não generaliza bem para dados de teste (ou seja, não consegue prever bem os dados de teste) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilando o modelo com o otimizador adam que é um otimizador estocástico de gradiente descendente\n",
    "modelo.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "modelo.fit(x_treinar, y_treinar, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador Adam\n",
    "\n",
    "- Otimizador Adam: é um otimizador que usa o gradiente estocástico para atualizar os pesos da rede neural, ele é baseado no algoritmo de Adam, que é um algoritmo de otimização estocástica baseado em estimativas adaptativas de momentos.\n",
    "\n",
    "### Modelo-fit\n",
    "\n",
    "- Modelo-fit: é o processo de treinamento do modelo, onde o modelo é ajustado aos dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o modelo com os dados de teste do futuro\n",
    "\n",
    "# preparndo alguns dados para testar o modelo\n",
    "teste_inicial = dt.datetime(2021,1,1) # data de inicio\n",
    "teste_final = dt.datetime.now() # data de hoje\n",
    "\n",
    "dados_teste = web.DataReader(banco, 'yahoo', teste_inicial, teste_final) # pega os dados do yahoo finance\n",
    "precos_reais = dados_teste['Close'].values # pega os valores de fechamento\n",
    "\n",
    "total_dados = pd.concat((dados['Close'], dados_teste['Close']), axis=0) # concatena os dados de treino e teste\n",
    "\n",
    "modelo_entradas = total_dados[len(total_dados) - len(dados_teste) - previsao_dias:].values # pega os dados de entrada\n",
    "modelo_entradas = modelo_entradas.reshape(-1,1) # redimensiona os dados\n",
    "modelo_entradas = normalizando.transform(modelo_entradas) # normaliza os dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total_dados = pd.concat((dados['Close'], dados_teste['Close']), axis=0)\n",
    "\n",
    "- O total_dados = pd.concat() é utilizado para concatenar os dados de treino e os dados de teste, ou seja, o total_dados é o conjunto de dados que será utilizado para treinar o modelo e para testar o modelo. o axis=0 é utilizado para concatenar os dados de forma vertical.\n",
    "\n",
    "### modelo_entrada\n",
    "\n",
    "- O modelo_entrada é o conjunto de dados que será utilizado para testar o modelo, ou seja, o conjunto de dados que será utilizado para que o modelo classifique os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo_entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo as previsões\n",
    "\n",
    "x_teste = []\n",
    "\n",
    "for x in range(previsao_dias, len(modelo_entradas)):\n",
    "    x_teste.append(modelo_entradas[x-previsao_dias:x, 0])\n",
    "\n",
    "x_teste = np.array(x_teste) # transformando em array numpy\n",
    "x_teste = np.reshape(x_teste, (x_teste.shape[0], x_teste.shape[1], 1)) # redimensionando os dados\n",
    "\n",
    "previsao_precos = modelo.predict(x_teste) # fazendo as previsões\n",
    "previsao_precos = normalizando.inverse_transform(previsao_precos) # desnormalizando os dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_teste = np.reshape(x_teste, (x_teste.shape[0], x_teste.shape[1], 1))\n",
    "\n",
    "- O x_teste = np.reshape() é utilizado para redimensionar o conjunto de dados que será utilizado para testar o modelo, ou seja, o conjunto de dados que será utilizado para que o modelo classifique os dados.\n",
    "\n",
    "### previsao_precos = modelo.predict(x_teste)\n",
    "\n",
    "- O previsao_precos = modelo.predict() é utilizado para prever os preços dos dados que serão utilizados para testar o modelo, ou seja, o conjunto de dados que será utilizado para que o modelo classifique os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representação gráfica dos dados\n",
    "\n",
    "plt.plot(precos_reais, color='red', label=f'Preço real {banco}')\n",
    "plt.plot(previsao_precos, color='green', label=f'Preço previsto {banco}')\n",
    "plt.title(f'{banco} Preço real x Preço previsto')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Preço do Ação')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando os dados de fechamento e colocando em x_treinar e y_treinar para prever os próximos dias\n",
    "dados_reais = [modelo_entradas[len(modelo_entradas) + 1 - previsao_dias:len(modelo_entradas+1), 0]] \n",
    "dados_reais = np.array(dados_reais) # transformando em array numpy\n",
    "dados_reais = np.reshape(dados_reais, (dados_reais.shape[0], dados_reais.shape[1], 1)) # redimensionando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dados_reais\n",
    "\n",
    "- A variável dados_reais é o conjunto de dados que foi utilizado para testar o modelo, ou seja, o conjunto de dados que foi utilizado para que o modelo classificasse os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados_reais.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = modelo.predict(dados_reais) # fazendo as previsões\n",
    "print(previsao)\n",
    "previsao = normalizando.inverse_transform(previsao) # desnormalizando os dados\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previsao = normalizando.inverse_transform(previsao)\n",
    "\n",
    "- O previsao = normalizando.inverse_transform() é utilizado para desnormalizar os dados que foram normalizados pois o modelo somente aceita dados normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Preço previsto para amanhã: {previsao}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "665796ea3363072d3a6057ac2fdbe3c4fcb0d17a4b92295d9707f78e9c46c0af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
